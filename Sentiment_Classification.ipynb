{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamto101/Natural-language-Processing/blob/main/Sentiment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2S8I2ny-ovS"
      },
      "source": [
        "# ANLP Assignment: Sentiment Classification\n",
        "\n",
        "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
        "\n",
        "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
        "\n",
        "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
        "\n",
        "Marking guidelines are provided as a separate document.\n",
        "\n",
        "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gXQAZas-l9c"
      },
      "outputs": [],
      "source": [
        "candidateno=22211789 #this MUST be updated to your candidate number so that you get a unique data sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk8JTP88A8vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3785aa7-e7ec-49ee-f09b-22b64698a689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "#preliminary imports\n",
        "\n",
        "#set up nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "#for setting up training and testing data\n",
        "import random\n",
        "\n",
        "#useful other tools\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from itertools import zip_longest\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.classify.api import ClassifierI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHBkzAccCVaZ"
      },
      "outputs": [],
      "source": [
        "#do not change the code in this cell\n",
        "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
        "    \"\"\"\n",
        "    Given corpus generator and ratio:\n",
        "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
        "\n",
        "    :param data: A corpus generator.\n",
        "    :param ratio: The proportion of training documents (default 0.7)\n",
        "    :return: a pair (tuple) of lists where the first element of the \n",
        "            pair is a list of the training data and the second is a list of the test data.\n",
        "    \"\"\"\n",
        "    \n",
        "    data = list(data)  \n",
        "    n = len(data)  \n",
        "    train_indices = random.sample(range(n), int(n * ratio))          \n",
        "    test_indices = list(set(range(n)) - set(train_indices))    \n",
        "    train = [data[i] for i in train_indices]           \n",
        "    test = [data[i] for i in test_indices]             \n",
        "    return (train, test)                       \n",
        " \n",
        "\n",
        "def get_train_test_data():\n",
        "    \n",
        "    #get ids of positive and negative movie reviews\n",
        "    pos_review_ids=movie_reviews.fileids('pos')\n",
        "    neg_review_ids=movie_reviews.fileids('neg')\n",
        "   \n",
        "    #split positive and negative data into training and testing sets\n",
        "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
        "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
        "    #add labels to the data and concatenate\n",
        "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
        "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
        "   \n",
        "    return training, testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3LWwBYICPP"
      },
      "source": [
        "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJLegkdPFUJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aacd4c42-c7d2-4be7-8cb0-a25d1ed0498f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount of training data is 1400\n",
            "The amount of testing data is 600\n",
            "The representation of a single data item is below\n",
            "(['matthew', 'broderick', 'and', 'high', 'school', ...], 'pos')\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "random.seed(candidateno)\n",
        "training_data,testing_data=get_train_test_data()\n",
        "print(\"The amount of training data is {}\".format(len(training_data)))\n",
        "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
        "print(\"The representation of a single data item is below\")\n",
        "print(training_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbTq6eGv2XT2"
      },
      "source": [
        "1)  \n",
        "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
        "\n",
        "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
        "\n",
        "c) **Explain** what you have done and why\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(filtered):\n",
        "  filter_words = [word for word in filtered if word.isalpha() and word not in stop]\n",
        "  return filter_words\n",
        "\n",
        "remove_stopwords(training_data[0][0])\n"
      ],
      "metadata": {
        "id": "Ozd2FzUu4H8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98a9194-b21f-45ea-f510-72b5ab69fc1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['matthew',\n",
              " 'broderick',\n",
              " 'high',\n",
              " 'school',\n",
              " 'comedy',\n",
              " 'two',\n",
              " 'terms',\n",
              " 'practically',\n",
              " 'inseparable',\n",
              " 'since',\n",
              " 'ferris',\n",
              " 'buehler',\n",
              " 'took',\n",
              " 'day',\n",
              " 'years',\n",
              " 'later',\n",
              " 'broderick',\n",
              " 'another',\n",
              " 'high',\n",
              " 'school',\n",
              " 'comedy',\n",
              " 'election',\n",
              " 'show',\n",
              " 'world',\n",
              " 'ferris',\n",
              " 'buehler',\n",
              " 'day',\n",
              " 'showed',\n",
              " 'educational',\n",
              " 'setting',\n",
              " 'similar',\n",
              " 'pile',\n",
              " 'marshmallows',\n",
              " 'light',\n",
              " 'fluffy',\n",
              " 'tasty',\n",
              " 'sparkling',\n",
              " 'clean',\n",
              " 'election',\n",
              " 'far',\n",
              " 'different',\n",
              " 'production',\n",
              " 'dark',\n",
              " 'frighteningly',\n",
              " 'realistic',\n",
              " 'one',\n",
              " 'much',\n",
              " 'entertain',\n",
              " 'minutes',\n",
              " 'occupies',\n",
              " 'shocks',\n",
              " 'well',\n",
              " 'jim',\n",
              " 'mcallister',\n",
              " 'matthew',\n",
              " 'broderick',\n",
              " 'type',\n",
              " 'teacher',\n",
              " 'makes',\n",
              " 'american',\n",
              " 'high',\n",
              " 'schools',\n",
              " 'proud',\n",
              " 'kind',\n",
              " 'caring',\n",
              " 'younger',\n",
              " 'man',\n",
              " 'built',\n",
              " 'life',\n",
              " 'around',\n",
              " 'carver',\n",
              " 'high',\n",
              " 'school',\n",
              " 'turn',\n",
              " 'carver',\n",
              " 'high',\n",
              " 'school',\n",
              " 'provided',\n",
              " 'home',\n",
              " 'jim',\n",
              " 'teacher',\n",
              " 'year',\n",
              " 'less',\n",
              " 'three',\n",
              " 'times',\n",
              " 'year',\n",
              " 'span',\n",
              " 'well',\n",
              " 'respected',\n",
              " 'social',\n",
              " 'studies',\n",
              " 'teacher',\n",
              " 'among',\n",
              " 'student',\n",
              " 'body',\n",
              " 'tracy',\n",
              " 'flick',\n",
              " 'reese',\n",
              " 'witherspoon',\n",
              " 'intelligent',\n",
              " 'outgoing',\n",
              " 'quote',\n",
              " 'film',\n",
              " 'super',\n",
              " 'nice',\n",
              " 'young',\n",
              " 'girl',\n",
              " 'involved',\n",
              " 'numerous',\n",
              " 'extracurricular',\n",
              " 'activities',\n",
              " 'always',\n",
              " 'hand',\n",
              " 'first',\n",
              " 'class',\n",
              " 'extremely',\n",
              " 'popular',\n",
              " 'among',\n",
              " 'student',\n",
              " 'body',\n",
              " 'natural',\n",
              " 'progression',\n",
              " 'decides',\n",
              " 'run',\n",
              " 'school',\n",
              " 'president',\n",
              " 'metzler',\n",
              " 'family',\n",
              " 'extremely',\n",
              " 'wealthy',\n",
              " 'one',\n",
              " 'father',\n",
              " 'dick',\n",
              " 'holmes',\n",
              " 'osborne',\n",
              " 'owns',\n",
              " 'cement',\n",
              " 'company',\n",
              " 'mother',\n",
              " 'jo',\n",
              " 'jeanine',\n",
              " 'jackson',\n",
              " 'ideal',\n",
              " 'housewife',\n",
              " 'two',\n",
              " 'children',\n",
              " 'paul',\n",
              " 'chris',\n",
              " 'klein',\n",
              " 'tammy',\n",
              " 'jessica',\n",
              " 'campbell',\n",
              " 'students',\n",
              " 'carver',\n",
              " 'high',\n",
              " 'school',\n",
              " 'paul',\n",
              " 'quarterback',\n",
              " 'football',\n",
              " 'team',\n",
              " 'injured',\n",
              " 'definitely',\n",
              " 'candidate',\n",
              " 'popular',\n",
              " 'person',\n",
              " 'school',\n",
              " 'tammy',\n",
              " 'lesbian',\n",
              " 'say',\n",
              " 'least',\n",
              " 'going',\n",
              " 'period',\n",
              " 'self',\n",
              " 'discovery',\n",
              " 'reasons',\n",
              " 'revenge',\n",
              " 'hatred',\n",
              " 'sexual',\n",
              " 'envy',\n",
              " 'jim',\n",
              " 'convinces',\n",
              " 'paul',\n",
              " 'run',\n",
              " 'tracy',\n",
              " 'school',\n",
              " 'president',\n",
              " 'claims',\n",
              " 'democracy',\n",
              " 'need',\n",
              " 'choices',\n",
              " 'tracy',\n",
              " 'run',\n",
              " 'unopposed',\n",
              " 'creates',\n",
              " 'dictatorship',\n",
              " 'sorts',\n",
              " 'paul',\n",
              " 'agrees',\n",
              " 'race',\n",
              " 'effort',\n",
              " 'spite',\n",
              " 'two',\n",
              " 'candidates',\n",
              " 'tammy',\n",
              " 'announces',\n",
              " 'running',\n",
              " 'well',\n",
              " 'campaign',\n",
              " 'straightforward',\n",
              " 'people',\n",
              " 'run',\n",
              " 'put',\n",
              " 'college',\n",
              " 'applications',\n",
              " 'nothing',\n",
              " 'well',\n",
              " 'even',\n",
              " 'want',\n",
              " 'go',\n",
              " 'college',\n",
              " 'says',\n",
              " 'election',\n",
              " 'good',\n",
              " 'guys',\n",
              " 'almost',\n",
              " 'everyone',\n",
              " 'agenda',\n",
              " 'matter',\n",
              " 'deeply',\n",
              " 'hidden',\n",
              " 'production',\n",
              " 'digs',\n",
              " 'exploits',\n",
              " 'audience',\n",
              " 'tracy',\n",
              " 'type',\n",
              " 'person',\n",
              " 'remember',\n",
              " 'high',\n",
              " 'school',\n",
              " 'girl',\n",
              " 'would',\n",
              " 'labeled',\n",
              " 'likely',\n",
              " 'achieve',\n",
              " 'anything',\n",
              " 'wants',\n",
              " 'yearbook',\n",
              " 'everyone',\n",
              " 'secretly',\n",
              " 'envied',\n",
              " 'jim',\n",
              " 'teacher',\n",
              " 'takes',\n",
              " 'trust',\n",
              " 'students',\n",
              " 'give',\n",
              " 'privilege',\n",
              " 'uses',\n",
              " 'amoral',\n",
              " 'advantage',\n",
              " 'everyone',\n",
              " 'including',\n",
              " 'principal',\n",
              " 'former',\n",
              " 'teacher',\n",
              " 'candidates',\n",
              " 'even',\n",
              " 'paul',\n",
              " 'girlfriend',\n",
              " 'two',\n",
              " 'sided',\n",
              " 'characters',\n",
              " 'much',\n",
              " 'film',\n",
              " 'beauty',\n",
              " 'typical',\n",
              " 'good',\n",
              " 'guys',\n",
              " 'hollywood',\n",
              " 'likes',\n",
              " 'instead',\n",
              " 'realistic',\n",
              " 'portrayal',\n",
              " 'real',\n",
              " 'world',\n",
              " 'specializing',\n",
              " 'revealing',\n",
              " 'type',\n",
              " 'sexual',\n",
              " 'perversions',\n",
              " 'people',\n",
              " 'usually',\n",
              " 'keep',\n",
              " 'matthew',\n",
              " 'broderick',\n",
              " 'perfect',\n",
              " 'role',\n",
              " 'character',\n",
              " 'often',\n",
              " 'similar',\n",
              " 'bill',\n",
              " 'murray',\n",
              " 'award',\n",
              " 'winning',\n",
              " 'role',\n",
              " 'film',\n",
              " 'rushmore',\n",
              " 'two',\n",
              " 'acting',\n",
              " 'jobs',\n",
              " 'broderick',\n",
              " 'far',\n",
              " 'superior',\n",
              " 'even',\n",
              " 'overshadowed',\n",
              " 'young',\n",
              " 'reese',\n",
              " 'witherspoon',\n",
              " 'hatred',\n",
              " 'causes',\n",
              " 'audience',\n",
              " 'develop',\n",
              " 'towards',\n",
              " 'simply',\n",
              " 'indescribable',\n",
              " 'broderick',\n",
              " 'witherspoon',\n",
              " 'simply',\n",
              " 'best',\n",
              " 'playing',\n",
              " 'various',\n",
              " 'scenes',\n",
              " 'one',\n",
              " 'moment',\n",
              " 'occurs',\n",
              " 'approaches',\n",
              " 'car',\n",
              " 'leaving',\n",
              " 'school',\n",
              " 'one',\n",
              " 'day',\n",
              " 'see',\n",
              " 'self',\n",
              " 'pride',\n",
              " 'eyes',\n",
              " 'presents',\n",
              " 'list',\n",
              " 'signatures',\n",
              " 'making',\n",
              " 'eligible',\n",
              " 'candidate',\n",
              " 'subtle',\n",
              " 'disgust',\n",
              " 'apparent',\n",
              " 'although',\n",
              " 'tries',\n",
              " 'mask',\n",
              " 'lines',\n",
              " 'attempts',\n",
              " 'put',\n",
              " 'happy',\n",
              " 'face',\n",
              " 'supporting',\n",
              " 'cast',\n",
              " 'one',\n",
              " 'little',\n",
              " 'hollywood',\n",
              " 'experience',\n",
              " 'far',\n",
              " 'apparent',\n",
              " 'everyone',\n",
              " 'takes',\n",
              " 'control',\n",
              " 'part',\n",
              " 'however',\n",
              " 'real',\n",
              " 'treat',\n",
              " 'jessica',\n",
              " 'campbell',\n",
              " 'confused',\n",
              " 'role',\n",
              " 'young',\n",
              " 'homosexual',\n",
              " 'girl',\n",
              " 'never',\n",
              " 'apparent',\n",
              " 'scene',\n",
              " 'delivers',\n",
              " 'speech',\n",
              " 'announcing',\n",
              " 'called',\n",
              " 'platform',\n",
              " 'presidency',\n",
              " 'marvelous',\n",
              " 'hatred',\n",
              " 'towards',\n",
              " 'thinks',\n",
              " 'unjust',\n",
              " 'system',\n",
              " 'expressed',\n",
              " 'ferris',\n",
              " 'buehler',\n",
              " 'made',\n",
              " 'feel',\n",
              " 'good',\n",
              " 'american',\n",
              " 'high',\n",
              " 'schools',\n",
              " 'gave',\n",
              " 'innocent',\n",
              " 'laugh',\n",
              " 'two',\n",
              " 'movie',\n",
              " 'achieved',\n",
              " 'goal',\n",
              " 'dare',\n",
              " 'think',\n",
              " 'election',\n",
              " 'goals',\n",
              " 'similar',\n",
              " 'real',\n",
              " 'portrayal',\n",
              " 'high',\n",
              " 'school',\n",
              " 'characters',\n",
              " 'real',\n",
              " 'world',\n",
              " 'certainly',\n",
              " 'pile',\n",
              " 'marshmallows']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXHrtNCg2XT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1097d5-d4fc-478e-de5b-6c812112d3cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(FreqDist({'slade': 15, 'film': 13, 'rock': 13, 'really': 11, 'like': 11, 'era': 11, 'glam': 9, 'one': 8, 'movement': 8, 'wild': 8, ...}),\n",
              " 'pos')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "from nltk.corpus.reader import wordlist\n",
        "training_data2 = [(FreqDist(remove_stopwords(wordlist)),label) for (wordlist,label) in training_data]\n",
        "testing_data2 = [(FreqDist(remove_stopwords(wordlist)), label) for (wordlist,label) in testing_data]\n",
        "\n",
        "testing_data2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvFu36xZ2XT5"
      },
      "outputs": [],
      "source": [
        "\n",
        "positive_frequency = FreqDist()\n",
        "negative_frequency = FreqDist()\n",
        "\n",
        "for review,label in training_data2:\n",
        "  if label == 'pos':\n",
        "    positive_frequency+=review\n",
        "  else:\n",
        "    negative_frequency+=review\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_frequencyy = FreqDist()\n",
        "negative_frequencyy = FreqDist()\n",
        "\n",
        "for review,label in testing_data2:\n",
        "  if label == 'pos':\n",
        "    positive_frequencyy+=review\n",
        "  else:\n",
        "    negative_frequencyy+=review"
      ],
      "metadata": {
        "id": "mECb97XYMO9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgePc9hV2XT_"
      },
      "outputs": [],
      "source": [
        "def content_words(positive,negative,b):\n",
        "    difference = positive - negative\n",
        "    most_common_diff = difference.most_common()\n",
        "    words = [word for (word,freq) in most_common_diff[:b]]\n",
        "    return words\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_words = content_words(negative_frequency,positive_frequency,10)\n",
        "print(neg_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBvzZdEdlldL",
        "outputId": "b36ef50f-2361-4b79-d859-28d44a9331b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['movie', 'bad', 'plot', 'script', 'worst', 'boring', 'even', 'get', 'nothing', 'could']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_words = content_words(positive_frequency,negative_frequency,10)\n",
        "print(pos_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcohqWbEtT2s",
        "outputId": "6e31cff0-29b3-4023-e713-6b06355c99c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['film', 'life', 'also', 'one', 'great', 'world', 'well', 'many', 'story', 'best']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JauTzY5N2XUB"
      },
      "source": [
        "**Explanation**\n",
        "\n",
        "To generate content words, The training data needs to be preprocessed. preprocessing data is essential because we need to transform the dataset from dirty data to clean data which will make the models accurate. in this assignment the stopwords function from nltk was used to unnecessary words and punctuations in order to give more focus to important words. \n",
        "\n",
        "i also used the FreqDist function to turn the training data into a bag of words representation. this will enable us see the words and the frequency. the next step was to use a for loop to divide the words from the training data into postive frequuency and negative frequency datasets. \n",
        "\n",
        "The next step was to generate a function that takes three parameters, gets the difference of first two parameters and  return most common words in the difference. \n",
        "\n",
        "the list of positive words was created by passing the function and putting the positive frequency and negative frequency(in that order), and the number of words needed.\n",
        "\n",
        "the list of negative words was created by passing the function and putting the negative frequency and positive frequency(in that order), and the number of words needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApOQE6vND20"
      },
      "source": [
        "2) \n",
        "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
        "\n",
        "b) **Explain** what you have done.\n",
        "\n",
        "[12.5\\%]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BThDMrcmODJy"
      },
      "outputs": [],
      "source": [
        "\n",
        "from nltk.classify.api import ClassifierI\n",
        "import random\n",
        "\n",
        "class Wordlistclassifier(ClassifierI):\n",
        "\n",
        "\n",
        "  def __init__(self,pos,neg):\n",
        "    self.__pos = pos\n",
        "    self.__neg = neg\n",
        "\n",
        "  def classify(self,doc):\n",
        "    score = 0 \n",
        "\n",
        "    for word,value in doc.items():\n",
        "        if word in self.__pos:\n",
        "          score += value\n",
        "        if word in self.__neg:\n",
        "          score -= value\n",
        "\n",
        "    return \"neg\" if score < 0 else \"pos\"\n",
        "\n",
        "\n",
        "  def labels(self):\n",
        "      return(\"pos\",\"neg\")\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Wordlistclassifier(pos_words,neg_words)\n"
      ],
      "metadata": {
        "id": "PZh-vwma-oNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(FreqDist(\"The movie is awful\".split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Sy5Rcps9IKew",
        "outputId": "92f99ac0-100e-49b8-d475-ac8158a8e1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To compare the performance of the naive bayes classifier and the word list classifier, we would"
      ],
      "metadata": {
        "id": "GWgOdXLxqWLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "\n",
        "To generate a word list classifier, i created a class object and passed in ClassfierI. \n",
        "\n",
        "Three methods were defined, the first method had attributes of positive and negative. In the second method, the score was set to zero. Then a for loop was created for words,value in Frequency Distribution. \n",
        "\n",
        "If the word is positive, the score should be incremented by the value. and if the word is negative , the word should be reduced by the value. this means the word list classifer should return negative if the score is less than zero. and it should return positive if the score is greated than zero.\n",
        "\n",
        "The Word list classifer has been generate to detect positive reviews as postive and negative reviews as negative."
      ],
      "metadata": {
        "id": "dni99LdiVca9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6vK5Vyz2XUF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZdDO_Y92XUH"
      },
      "source": [
        "3)\n",
        "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
        "\n",
        "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LQc8bsA2XUI"
      },
      "outputs": [],
      "source": [
        "def accuracy_tester(cls,test_data):\n",
        "  acc = 0 \n",
        "  docs,goldstandard = zip(*testing_data2)\n",
        "  predictions = cls.classify_many(docs)\n",
        "  for prediction,goldlabel in zip(predictions,goldstandard):\n",
        "    if prediction == goldlabel:\n",
        "        acc+=1\n",
        "  print(len(predictions))\n",
        "  print(len(goldstandard))\n",
        "  return acc/(len(test_data))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = accuracy_tester(classifier, testing_data2)  \n",
        "print(score)"
      ],
      "metadata": {
        "id": "lSImW0Imy1HV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390f6587-a19b-4111-f6ee-bbbd8f7ad2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600\n",
            "600\n",
            "0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_i80ceP2XUJ"
      },
      "outputs": [],
      "source": [
        "class ConfusionMatrix:\n",
        "  def __init__ (self,predictions,goldstandard,classes = ('pos','neg')):\n",
        "\n",
        "      (self.c1,self.c2) = classes\n",
        "      self.TP = 0\n",
        "      self.FP = 0\n",
        "      self.TN = 0\n",
        "      self.FN = 0\n",
        "      for p,g in zip(predictions,goldstandard):\n",
        "        if g == self.c1:\n",
        "            if p == self.c1:\n",
        "                self.TP+=1\n",
        "            else:\n",
        "                self.FN+=1\n",
        "\n",
        "        elif p == self.c1:\n",
        "            self.FP+=1\n",
        "        else:\n",
        "            self.TN+=1\n",
        "\n",
        "\n",
        "  def precision(self):\n",
        "          p = 0\n",
        "          p = self.TP/ (self.TP + self.FP)\n",
        "          print(p)\n",
        "          return p\n",
        "\n",
        "  def recall(self):\n",
        "          r = 0\n",
        "          r = self.TP / (self.TP + self.FN)\n",
        "          return r \n",
        "\n",
        "  def F1(self):\n",
        "        f1 = 0\n",
        "        p = self.precision()\n",
        "        r = self.recall()\n",
        "        f1 = (2 * p * r )/(p + r)\n",
        "        return f1 \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbYwwhcs2XUL"
      },
      "outputs": [],
      "source": [
        "docs,labels = zip(*testing_data2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = classifier.classify_many(docs)"
      ],
      "metadata": {
        "id": "_CbvEHJUuNyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculation = ConfusionMatrix(classifier.classify_many(docs),labels)"
      ],
      "metadata": {
        "id": "W3W3jPzpwqZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculation.TP)\n",
        "print(calculation.FP)\n",
        "print(calculation.TN)\n",
        "print(calculation.FN)"
      ],
      "metadata": {
        "id": "2uHtqxfuwqd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea55273b-0896-40b7-fb8e-17253933ea13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275\n",
            "191\n",
            "109\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculation.precision()\n"
      ],
      "metadata": {
        "id": "AB3OpwCXwqiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771770b3-4643-41f2-8416-7a2d13cbd288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5901287553648069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5901287553648069"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculation.recall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGOGYgsadUfd",
        "outputId": "692f2031-a781-4bc7-b9d5-9a836169bd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9166666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculation.F1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeW7qJhadXqb",
        "outputId": "280d070e-e096-4821-a063-fd40d8cbe3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5901287553648069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7180156657963446"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVZp0N5J2XUL"
      },
      "source": [
        "Explanation\n",
        "\n",
        "No it is not reasonable to evaluate classfiers by accuracy. When it comes to evaluation of the classifier, accuracy is not the best indicator, This is because of class imbalance\n",
        "\n",
        "Class Imbalance occurs when one class (the minority class) contains fewer samples than the other class,(the majority class).\n",
        "\n",
        "When there is class imbalance, the classifier can get high accuracy by predicting the majority class and it fails to predict the minority class.\n",
        "\n",
        "This is because accuracy gives a single measure of how well the classifier is working within one class and it does not tell how well the classifier works within seperate classes.\n",
        "\n",
        "An example can be spam detection. in the emails, 95 percent are not spam, 5 percent are spam. if a classifier is 95 percent accurate in detecting spam and it predicts all the emails as non-spam. it means the classifier might only be doing well enough to predict the majority class that is 95 percent. \n",
        "\n",
        "The classifier might not be doing well enough to predict the minority class of 5 percent spam. T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS9UpmJNEAp"
      },
      "source": [
        "4) \n",
        "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
        "\n",
        "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results. \n",
        "\n",
        "[12.5\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gwjig-Y12XUN"
      },
      "outputs": [],
      "source": [
        "naive_bayes_classifier = nltk.NaiveBayesClassifier.train(training_data2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AUsYRMa2XUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15d30c3-067e-407e-f279-0913acf4a66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.68\n",
            "Most Informative Features\n",
            "               insulting = 1                 neg : pos    =     15.0 : 1.0\n",
            "             beautifully = 1                 pos : neg    =     13.0 : 1.0\n",
            "             wonderfully = 1                 pos : neg    =     12.7 : 1.0\n",
            "                   lousy = 1                 neg : pos    =     11.0 : 1.0\n",
            "                   sucks = 1                 neg : pos    =     11.0 : 1.0\n",
            "                terrific = 2                 pos : neg    =     11.0 : 1.0\n",
            "               ludicrous = 1                 neg : pos    =     10.2 : 1.0\n",
            "            breathtaking = 1                 pos : neg    =     10.2 : 1.0\n",
            "                     bad = 5                 neg : pos    =      9.7 : 1.0\n",
            "                  avoids = 1                 pos : neg    =      9.7 : 1.0\n",
            "                    slip = 1                 pos : neg    =      9.7 : 1.0\n",
            "               uplifting = 1                 pos : neg    =      9.7 : 1.0\n",
            "             outstanding = 1                 pos : neg    =      9.2 : 1.0\n",
            "                  boring = 2                 neg : pos    =      9.0 : 1.0\n",
            "            construction = 1                 pos : neg    =      9.0 : 1.0\n",
            "              astounding = 1                 pos : neg    =      9.0 : 1.0\n",
            "                  giving = 2                 pos : neg    =      9.0 : 1.0\n",
            "             maintaining = 1                 pos : neg    =      9.0 : 1.0\n",
            "                    song = 2                 pos : neg    =      9.0 : 1.0\n",
            "                  stupid = 2                 neg : pos    =      8.6 : 1.0\n"
          ]
        }
      ],
      "source": [
        "print(nltk.classify.accuracy(naive_bayes_classifier,testing_data2))\n",
        "naive_bayes_classifier.show_most_informative_features(20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare the performance of the naives bayes classifier and the word list classifier. i will check some of the words that the naive bayes has called negative and positive with the word list classifier to see if the word list classifier will term it negative or positive\n",
        "\n",
        "Above we can see the naive bayes most informative features\n",
        "\n",
        "naive bayes negative words : lousy,sucks,insulting\n",
        "\n",
        "\n",
        "naive bayes positive words:  beautifully, wonderfully, terrific\n",
        "\n",
        "\n",
        "i will now pass these words in sentences into the word list classifier to see the review from the word list classifier\n"
      ],
      "metadata": {
        "id": "kAGU6feLqjQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(FreqDist(\"The film is lousy\".split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CuOkSfY0otUr",
        "outputId": "42e8d08f-e2a1-4159-f0bb-7acd568482fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(FreqDist(\"This movie sucks\".split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pv_XveWIr0Gr",
        "outputId": "67053c8d-8e1f-4ab1-dcb3-01ca954580da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(FreqDist(\"The film is insulting\".split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RdbnwYAvr-r0",
        "outputId": "91c13402-1e24-4f74-fca2-37838028e2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bytPkuHf2XUO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(FreqDist(\"The movie is beautifully made\".split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7QYfF0DcsFlj",
        "outputId": "ad7ec63e-3d80-4fdc-a9c9-79872bd0733a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(FreqDist(\"The movie is wonderfully made\".split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BfeBJKWrsF0m",
        "outputId": "7d2fb2e1-8294-4ca0-9ae0-4c870ea38b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(FreqDist(\"The film is terrific\".split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XnuVqmXPsGA6",
        "outputId": "78e0db2b-005f-44cb-a677-da504c267b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results.\n",
        "\n",
        "The words the naive bayes classifier classified as positive and negative words are correct according to the usuage in real life. \n",
        "\n",
        "However the word list classifier classified words which are positive as negative and words which are nagative as positive. \n",
        "\n",
        "The underlying problem could be due to the fact that the word list classifier classified a word which actually has no positive or negative emotion attached to it in real life as a negative word or a positive word, so any other words put in the same sentence with that word(which was classfied as a negative or positive word) becomes a negative or positive review."
      ],
      "metadata": {
        "id": "s-UD2Sb8sr4l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGDXaVDqOSfY"
      },
      "source": [
        "5) \n",
        "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions. \n",
        "\n",
        "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
        "\n",
        "[25\\%]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlxoUthX2XUP"
      },
      "source": [
        "Recommendation.\n",
        "\n",
        "I would recommend a naive bayes classifier for future work in classification.\n",
        "\n",
        "Naives Bayes classifier is easier to implent: This is means it requires less code compared to the word list classifier.writing the code for the wordlist classifier took me longer time to understand and write. but with the naive bayes i understood it in a short time and implemented it.\n",
        "\n",
        "Naives Bayes Classifier is faster: it is faster to run because it requires less amount of code to run so it can be completed in shorter amount of time which makes the work more efficient.\n",
        "\n",
        "Naives Bayes Classifier can handle big datasets: The naives bayes classifier showed better accuarcy in handling the words compared to the word list classifier. it accuartely classified negative words as negative and positive words as positive meanwhile the word list classifier did not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1L7mZ-k2XUQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFeOWIRm2XUQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT82P88M2XUQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym-TGvYS2XUR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34rdlS_iPov6",
        "outputId": "b256e993-aae6-4bb3-a310-c86474ea3d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Submission length is 812\n"
          ]
        }
      ],
      "source": [
        "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
        "##Running it before providing any answers shows that the questions have a word count of 437\n",
        "\n",
        "import io\n",
        "from nbformat import current\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#filepath=\"/content/drive/My Drive/NLE Notebooks/assessment/assignment1.ipynb\"\n",
        "filepath=\"/content/drive/My Drive/AppNLP_Notebooks/22211789.ipynb\"\n",
        "question_count=437\n",
        "\n",
        "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
        "    nb = current.read(f, 'json')\n",
        "\n",
        "word_count = 0\n",
        "for cell in nb.worksheets[0].cells:\n",
        "    if cell.cell_type == \"markdown\":\n",
        "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
        "print(\"Submission length is {}\".format(word_count-question_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtqCcG6wPsmf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}